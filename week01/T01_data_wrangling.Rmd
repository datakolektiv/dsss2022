---
title: "DSSS2022 Machine Learning in R: Task List 01"
output: html_notebook
author: Goran S. Milovanovic, DataKolektiv
---

![](DK_Logo_White_150.png)

# Data Wrangling in tidyverse

We will exercise our [tidyverse](https://www.tidyverse.org/) skills a bit here!

You may rely on [R for Data Science](https://r4ds.had.co.nz/), chapter [5 Data Transformation](https://r4ds.had.co.nz/transform.html), as well as our [05_tidyverse.R](https://github.com/datakolektiv/dsss2022/blob/main/week01/05_tidyverse.R) script for this exercise.

### tidyverse

We need to have access to the tidyverse functions, of course:

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
```

### The dataset

[Google Dataset Search](https://datasetsearch.research.google.com/) is great resource of awesome datasets that you can use for practice or research purposes. I have found this very interesting [Coronovirus COVID-19 related dataset](https://datasetsearch.research.google.com/search?src=3&query=coronavirus%20covid-19&docid=L2cvMTFqOWI4MTRjdA%3D%3D) there: [Our World in Data - COVID-19 Data Explorer](https://ourworldindata.org/explorers/coronavirus-data-explorer):

- [Dataset GitHub repository](https://github.com/owid/covid-19-data/tree/master/public/data)
- [Dataset CSV file](https://covid.ourworldindata.org/data/owid-covid-data.csv)

based on: 

> Mathieu, E., Ritchie, H., Ortiz-Ospina, E. et al. A global database of COVID-19 vaccinations. Nat Hum Behav (2021). https://doi.org/10.1038/s41562-021-01122-8.

We can access the `CSV` file directly from R's `read.csv()`, as we have demonstrated in the classroom on Saturday, June 4:

```{r echo=TRUE, warning=FALSE, message=FALSE}
file_url <- "https://covid.ourworldindata.org/data/owid-covid-data.csv"
data_set <- read.csv(file_url, 
                     header = TRUE,
                     check.names = FALSE,
                     stringsAsFactors = FALSE)
head(data_set)
```

Let's inspect the variables present here. **N.B.** A thorough description of the dataset is given in its [GitHub repo](https://github.com/owid/covid-19-data/tree/master/public/data).

```{r echo=TRUE, warning=FALSE, message=FALSE}
glimpse(data_set)
```

### Task 1. 

Use `table()` and `as.data.frame` to produce a frequency distribution of `data_set$location`: that is how we will learn how many data points do we have per country (but for the World in general, as you might have observed that `World` is a value found in `data_set$location` as well). Name your data.frame: `country_frame`. Please give some nice names - `country` and `observations` - to your resulting data.frame's columns and print out the result's first twenty rows. Print the unique number of countries present in your.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 2. 

You may have noticed that not only `World`, but `Europe`, `European Union`, `Asia` etc. are also values in the `data_set$location` column. But if we need a per-country analysis of the data, then we need to remove such entries. Luckily, I have found out that all values in the `data_set$iso_code` column for such entires begin with `OWID_`. Please remove all entries that have values begininng with `OWID_` in the `data_set$iso_code` column from the `data_set` data.frame using `filter()` and `grepl()` (**hint:** `"^OWID_", we mentioned this in the classroom on June 4). Reproduce the `country_frame` data.frame from Task 1 without these entries and check out how many countries are now present.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 3. 

Use `substr()` to extract year from `data_set$date` and place it in a new column: `data_set$year`. The use `group_by()` and `summarise()` to compute the mean number of `new_cases` per country, per year, rounded on two decima places. Select only the variables that you need for this analysis in the beginning of your pipeline. Beware of the `NAs` in the data (**hint:** `na.rm` is an argument in what R functions...) and sort the result in the descending order of `mean_new_cases` by using `arrange()` (your variable where the mean of `new_cases` is found).

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 4. 

The dataset in front of us is a time series, of course: there is an observation for each day since the onset of the pandemic. So, it is quite possible that some values in columns such as `population` and `population_density` have changed with time, not to mention `new_cases` and similar. However, say that we want to take an approximate look at the relationship of `people_vaccinated`, `population`, `population_density`, `people_vaccinated_per_hundred`, `gdp_per_capita`, and `total_cases` - per country. What we need is a dataset that takes a country, and then the latest available observation for each of the mentioned variables. Use a `dplyr` pipeline to produce such a dataset and call it `country_analysis_frame`. **Hint:** make use of `slice_tail()` from dplyr. **NOTE.** It might be the case that some recent data points in the `people_vaccinated` column are missing; use `filter(!is.na(people_vaccinated))` at some point in your pipeline.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 5. 

You might have observed how your `country_analysis_frame` is full of `NAs`! So many missing values, disappointing indeed! Use a combination of `apply` over columns of `country_analysis_frame` and `is.na()` to find out the percent of missing values in each column in `country_analysis_frame`.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

Check your result: you should be able to find out that there is `86.9%` of missing data in the `people_vaccinated_per_hundred` column and `15.28%` of missing data in the `gdp_per_capita` column. Then... 

### Task 5A. 

Drop the following columns from `country_analysis_frame`: `people_vaccinated_per_hundred`, `date` using `select()` and print out the first then rows. **Hint:** use the `all_of()` dplyr helper function within your `select()` call.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 6.

Keep only complete observations (i.e. no `NA` values anywhere) in `country_analysis_frame`. You will need to learn about the [complete.cases()](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/complete.cases) function in order to do so. Reuse your `apply()` call from Task 4. in order to make sure that no missing values are left. How many countries are left in `country_analysis_frame`?

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```

### Task 7.

Produce a new variable, `proportion_vaccinated`, by dividing `people_vaccinated` by `population`; drop both `people_vaccinated` and `population` from the data.frame.

```{r echo=TRUE, warning=FALSE, message=FALSE}
# - Your code goes here : )
```


### Congratulations!

Here is your award: now that you have produced  the `country_analysis_frame`, the shape of things to come appears! Here is how to perform a multiple linear regression in an attempt to predict `total_cases_per_million` from the following predictors in `country_analysis_frame`: `proportion_vaccinated`, `population_density` and `gdp_per_capita`.

```{r echo=TRUE, warning=FALSE, message=FALSE, eval=FALSE}
mlr_model <- lm(total_cases_per_million ~ 
                  proportion_vaccinated + 
                  population_density + 
                  gdp_per_capita, 
                data = country_analysis_frame)
summary(mlr_model)
```

--- 

![](dsss2022_startit_add.jpg)
--- 

**Data Science Summer School 2022** <br>
**Machine Learning in R** <br>
DataKolektiv, Belgrade, June 2022.